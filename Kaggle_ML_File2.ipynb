{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle ML File.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBFh2DmcU5QbzCVw7H8yll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdivy/git_test/blob/main/Kaggle_ML_File2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-evvVSsepEx"
      },
      "source": [
        "Project Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_bLbnKydpBc"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data\n",
        "data = pd.read_csv('/content/CarPrice_project.csv')\n",
        "\n",
        "# Separate target from predictors\n",
        "y = data.price\n",
        "X = data.drop(['price'], axis=1)\n",
        "\n",
        "# Divide data into training and validation subsets\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\n",
        "# \"Cardinality\" means the number of unique values in a column\n",
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
        "                        X_train_full[cname].dtype == \"object\"]\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Keep selected columns only\n",
        "my_cols = categorical_cols + numerical_cols\n",
        "X_train = X_train_full[my_cols].copy()\n",
        "X_valid = X_valid_full[my_cols].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF2yLm1veKlM"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = SimpleImputer(strategy='constant')\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ssIDrWeNhn"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1j5laO-eNmX",
        "outputId": "4274e104-3312-406d-a029-0aaaaabaa865"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('model', model)\n",
        "                             ])\n",
        "\n",
        "# Preprocessing of training data, fit model \n",
        "my_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = mean_absolute_error(y_valid, preds)\n",
        "print('MAE:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 1871.9623575609758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuJo2RmHetYe"
      },
      "source": [
        "## Cross-Validation Techniques(No need to keep seperate train and validation sets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6rfTilohMTM",
        "outputId": "3154705c-1967-41a8-c5ab-c68cbb92a166"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['car_ID', 'symboling', 'CarName', 'fueltype', 'aspiration',\n",
              "       'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'wheelbase',\n",
              "       'carlength', 'carwidth', 'carheight', 'curbweight', 'enginetype',\n",
              "       'cylindernumber', 'enginesize', 'fuelsystem', 'boreratio', 'stroke',\n",
              "       'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg',\n",
              "       'price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVbsJWlqew_C"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data\n",
        "data = pd.read_csv('/content/CarPrice_project.csv')\n",
        "\n",
        "# Separate target from predictors\n",
        "y = data.price\n",
        "X = data.drop(['price'], axis=1)\n",
        "\n",
        "# Divide data into training and validation subsets\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\n",
        "# \"Cardinality\" means the number of unique values in a column\n",
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
        "                        X_train_full[cname].dtype == \"object\"]\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Keep selected columns only\n",
        "my_cols = categorical_cols + numerical_cols\n",
        "X_train = X_train_full[my_cols].copy()\n",
        "X_valid = X_valid_full[my_cols].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBa0W9L2gF3F"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
        "                              ('model', RandomForestRegressor(n_estimators=50,\n",
        "                                                              random_state=0))\n",
        "                             ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T4aEFj4gF15",
        "outputId": "65be4270-ed31-453c-d80b-28a210a6c5c5"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Multiply by -1 since sklearn calculates *negative* MAE\n",
        "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
        "                              cv=5,\n",
        "                              scoring='neg_mean_absolute_error')\n",
        "\n",
        "print(\"MAE scores:\\n\", scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE scores:\n",
            " [nan nan nan nan nan]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'honda civic'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'alfa-romero giulia'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'alfa-romero giulia'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'alfa-romero giulia'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Cannot use mean strategy with non-numeric data:\n",
            "could not convert string to float: 'alfa-romero giulia'\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fzZ2lNMgFzR",
        "outputId": "7d5f9300-4fdd-4b35-ed0d-4a11fb37b96c"
      },
      "source": [
        "print(\"Average MAE score (across experiments):\")\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average MAE score (across experiments):\n",
            "nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCW5oAqggFxY"
      },
      "source": [
        "def get_score(n_estimators):\n",
        "    my_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', SimpleImputer()),\n",
        "    ('model', RandomForestRegressor(n_estimators=n_estimators, random_state=0))\n",
        "])\n",
        "    scores = -1 * cross_val_score(my_pipeline, X, y,\n",
        "                              cv=3,\n",
        "                              scoring='neg_mean_absolute_error')\n",
        "    return scores.mean()\n",
        "# Check your answer\n",
        "step_1.check()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtcS2BfOAH_n"
      },
      "source": [
        "Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arhsFvZSFQZa"
      },
      "source": [
        "X = df.copy()\n",
        "y = X.pop(\"CompressiveStrength\")\n",
        "\n",
        "# Train and score baseline model\n",
        "baseline = RandomForestRegressor(criterion=\"mae\", random_state=0)\n",
        "baseline_score = cross_val_score(\n",
        "    baseline, X, y, cv=5, scoring=\"neg_mean_absolute_error\"\n",
        ")\n",
        "baseline_score = -1 * baseline_score.mean()\n",
        "\n",
        "print(f\"MAE Baseline Score: {baseline_score:.4}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fW18Ug-HVCn"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP_AzkkhHYMn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# Set Matplotlib defaults\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\n",
        "    \"axes\",\n",
        "    labelweight=\"bold\",\n",
        "    labelsize=\"large\",\n",
        "    titleweight=\"bold\",\n",
        "    titlesize=14,\n",
        "    titlepad=10,\n",
        ")\n",
        "\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"../input/fe-course-data/ames.csv\")\n",
        "\n",
        "\n",
        "# Utility functions from Tutorial\n",
        "def make_mi_scores(X, y):\n",
        "    X = X.copy()\n",
        "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
        "        X[colname], _ = X[colname].factorize()\n",
        "    # All discrete features should now have integer dtypes\n",
        "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "\n",
        "def plot_mi_scores(scores):\n",
        "    scores = scores.sort_values(ascending=True)\n",
        "    width = np.arange(len(scores))\n",
        "    ticks = list(scores.index)\n",
        "    plt.barh(width, scores)\n",
        "    plt.yticks(width, ticks)\n",
        "    plt.title(\"Mutual Information Scores\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXmCfYNvHhne"
      },
      "source": [
        "features = [\"YearBuilt\", \"MoSold\", \"ScreenPorch\"]\n",
        "sns.relplot(\n",
        "    x=\"value\", y=\"SalePrice\", col=\"variable\", data=df.melt(id_vars=\"SalePrice\", value_vars=features), facet_kws=dict(sharex=False),\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXsMQi_AHlJ5"
      },
      "source": [
        "X = df.copy()\n",
        "y = X.pop('SalePrice')\n",
        "\n",
        "mi_scores = make_mi_scores(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CcfevUpHlIl"
      },
      "source": [
        "print(mi_scores.head(20))\n",
        "# print(mi_scores.tail(20))  # uncomment to see bottom 20\n",
        "\n",
        "plt.figure(dpi=100, figsize=(8, 5))\n",
        "plot_mi_scores(mi_scores.head(20))\n",
        "# plot_mi_scores(mi_scores.tail(20))  # uncomment to see bottom 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw75Z0BFHlEb"
      },
      "source": [
        "sns.catplot(x=\"BldgType\", y=\"SalePrice\", data=df, kind=\"boxen\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTotw3yWHlDC"
      },
      "source": [
        "# YOUR CODE HERE: \n",
        "feature = \"GrLivArea\"\n",
        "\n",
        "sns.lmplot(\n",
        "    x=feature, y=\"SalePrice\", hue=\"BldgType\", col=\"BldgType\",\n",
        "    data=df, scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=4,\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z41txb8XLdnP"
      },
      "source": [
        "feature engineering methods\n",
        "\n",
        "\n",
        "\n",
        "*   Mathematical Transforms\n",
        "*   Counts\n",
        "\n",
        "\n",
        "*   Building-Up And Breaking-Down Features\n",
        "*   Group Transforms\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjqb8MmoLnes"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0eIQXTzZlm_"
      },
      "source": [
        "## Missing Values complete notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOheMkH2Zlkb"
      },
      "source": [
        "https://www.kaggle.com/divych13/handle-missing-values-only-notebook-you-need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q377M2ufZrX3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}